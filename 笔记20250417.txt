企业原始知识整理有什么特殊要求吗？比如统一知识文档格式啥的
Thinking：对于AI来说，什么格式是最友好的？
Markdown

企业会有很多文档格式，PPT, word, excel, pdf, png

Thinking：知识是存储在向量库还是其他库呢
=> 向量数据库 => 原文，embedding（相似度检索，找到最优价值的chunks）

Thinking：从原始文档切分成chunk是怎么做的？如果是人工分切，会不会每篇文章都看，效率太低。如果是基于规则，会不会导致信息流失，或者一个主题切分到2个chunk
1）指定规则，比如 chunk size =1000，overlap = 10%
句子
2) 语义上的切分

现成的RAG产品：
1）Cherry Studio
2) imacopilot
3) notebooklm
https://notebooklm.google.com/
4）钉钉助理
5）Coze

Embedding选择：
https://huggingface.co/spaces/mteb/leaderboard （Open, 闭源）

Thinking：在哪里找到开源的embedding模型
https://modelscope.cn/

用户的Query 会包括：
1）instruction 指令
2）知识

帮我查找 XXXX

Thinking：如何将文本转化成markdown
如果想要将PPT转化为Markdown，
1）对PPT里面的内容进行extract
2）对抽取出来的内容 放到Markdown中
如果是图像 => 使用 Qwen-VL进行理解

===
多模态的embedding

===
embedding
模型怎么部署在gpu上呢

在向量数据库中，可以有两个阶段
1）召回
2）重排
向量数据库中保存的chunk可能会有1000万个 => 召回快速筛选出 1000个 => 重排序 Top10
1000万 => Rank Top10
召回：就是快速采用多种策略进行粗筛的过程
策略1：基于关键词匹配 100
策略2：基于语义向量相似度 100

chatpdf-faiss代码中，使用了两个模型
1）推理模型 qwen-turbo
2）Embedding模型 text-embedding-v1

chunk策略：
chunk_size =1000, overlap =200，分割是按照标点符号进行分割（句号，换行）
docs = knowledgeBase.similarity_search(query)

THinking：为什么要分块？
如果不分块，整个文件作为一个基本单元。那么文件里面的内容会比较多 => 3072维的向量中

Thinking：企业做自己的知识库，会用这些大厂做的平台吗？比如coze
1）coze有企业版本, 4980/月
2）Dify开源
3）LangChain实现了qa_chain，可以用 faiss做向量数据库

Thinking：知识库回答不了的，在调用推理模型嘛？
知识库的作用是上下文，可能上下文中 没有用户提到的问题。
这时，你可以在prompt中说明，是否让LLM自己来进行回答；

Thinking：如果llm中没有相关知识，rag是不是就没有效果了
是的。

Thinking：chunks 是什么样的格式存储的
chunks 就是原文；chunk_embedding 3072维
===
这个文本块页码不对，帮我查看 文本块页码的计算逻辑，是否有问题


提示词优化：
1）人工规则 => 针对常见的Query，但是能设置的规则有限
2）LLM自己来思考

通过think => 优化了用户的提示词，让回答质量更高；
在企业实战中，遇到问题，思考解决的方法（策略）

Dify, Coze => 是不是可以回答用户问题，回答很好？


Thinking：RAG和chunk关联是什么
RAG 知识检索系统
chunk 分块，是知识的最小单位

Thinking：向量数据库是存储在本地文件夹下吗
knowledgeBase.save_local('./faiss-1')

Thinking：如果文档里 有文字和图片 怎么保证图片跟相关文字不会拆成2个chunk呢
如果PDF中有图片，需要先做预处理（将图片 转化为文本）
=> 转化为 全部的文本
再做chunk（chunk_size=1000, overlap=100）

总结 => 概要级的

LangChain 更灵活，个性化
dify 更方便
===
1、不同维度向量能计算相似度吗？还是会补充维度
需要变成统一维度

5、向量数据库和embedding模型是什么关系
向量数据库是一个软件，存储了很多 chunk的embedding，给你提供了 save, load, find_similarity的接口
embedding是一种向量格式（比如 3072维）

8、LLM可以兼容RAG吗，rag的优势怎么集成到LLM中
LLM（推理引擎） + RAG（外挂知识库）

===
🙋有像notebookLM之类的工具使用，什么情况下企业要自己做RAG？
数据安全性 => RAG私有化
如果知识是来自于网络 => 使用 notebookLM是更方便 (Gemini-embedding， Gemini-2.5, 召回和重排的策略，以及对每篇文档做了预处理：文档的概览 + 关键词）


Thinking：公司搭知识库，主要是PDF的一些标准规范，公司的积累的一些技术支持的问答（excel），开发积累的一些知识doc，想做个知识库，您建议用什么？问答质量好
如果想要质量好 => 开发工作少不了
也可以使用开源的Qwen-Agent  => RAG质量还是不错的 *****

当时客户使用 钉钉助理（类似Coze），打造了 XX助手；
我用Qwen-Agent 做了RAG助手，发现 Qwen-Agent的RAG质量 > 钉钉助理回答的质量

Thinking：个人想构建知识库，用于教学，资料主要是PPT，Word，Excel和PDF，如何低成本构建，并且可以保护知识产权？
先试试Qwen-Agent （效果还不错，而且是开源的）

Thinking：结构化的数据可以用Qwen-Agent吗，免得做传统的SQL开发
Text2SQL，可以在Qwen-Agent中设置 Tool
Qwen-Agent 不光是可以用于RAG，还可以让AI Agent调用各种Tool。针对结构化的数据，你可以做一个 Text2SQL的工具

Thinking：如果QWEN-AGENT非常的成熟的话，简单易做，那我们学RAG如何体现出我们自己的价值
现阶段 没有很成熟的RAG系统
Qwen-Agent只是一种Agent框架，（集成了一部分 RAG的策略，召回、重排、以及生成的策略）
=> Qwen-Agent 回答质量还可以 （比钉钉助理略好），但是不如  notebookLM
自己使用Qwen-Agent的话，也可以加很多其他的策略，比如对数据的预处理

Thinking：可以详细讲解下 智能文档技术图，在公司知识库项目中的具体实现吗？如企业中PDF、PPT的处理
LayoutLM, LayoutLLM
给PDF => LayoutLLM => 进行提问和理解 => 整理出来对PDF、PPT的理解，用于完善对应的知识 Markdown

Thinking：cherry studio和notebookLM分别在什么情况下使用
不需要自己开发的情况下，直接想要用现成的 RAG产品
cherry studio 在国内就可以用，开源
notebookLM是Google的产品，不开源，但免费

Thinking：知识图谱和知识库有什么区别
知识图谱 是用Graph的方式，将知识链接起来。 map = node, edge
我们就可以在知识图谱上，对知识进行计算，比如 姚明的女儿的身高是多少？
chunk1: 姚明的女儿叫 ABC
chunk2: ABC的身高是多少

Thinking：cherry studio和qwen-agent哪个RAG策略好？
cherry studio本身是个套壳产品，只是链接各种工具（LLM, MCP, RAG知识库）
qwen-agent：开源的框架，提供了一些tool, 提供一些RAG策略

Thinking：cherry studio调的哪个LLM进行回答？


>=3.10


课程中会到的python工具箱：
faiss, modelscope, langchain, langchain_community, PyPDF2
这些你在使用python的时候，如果遇到类似ModuleNotFoundError: No module named 'XXX'的错误，说明该模块尚未安装，需要使用pip install命令进行安装

faiss安装方法：
1）如果你有GPU环境，可以安装 faiss-gpu
pip install faiss-gpu
2）如果你是CPU环境，安装faiss-cpu
pip install faiss-cpu

